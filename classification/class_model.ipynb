{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-29T17:49:14.178922Z",
     "iopub.status.busy": "2025-04-29T17:49:14.178498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "# 1. Setup and Installs\n",
    "#------------------------------------------------------\n",
    "! pip install ultralytics -q # Install YOLOv8 library\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import yaml\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image # To display results later\n",
    "\n",
    "print(\"Setup Complete.\")\n",
    "\n",
    "#------------------------------------------------------\n",
    "# 2. Define Paths and Parameters\n",
    "#------------------------------------------------------\n",
    "# Input dataset path on Kaggle\n",
    "INPUT_DATASET_PATH = \"/kaggle/input/classification/dataset1/\"\n",
    "RIPE_IMG_DIR = os.path.join(INPUT_DATASET_PATH, \"Ripe\")\n",
    "\n",
    "# Output directory for prepared YOLO dataset (in Kaggle's writable directory)\n",
    "OUTPUT_YOLO_DATA_DIR = \"/kaggle/working/mango_yolo_dataset/\"\n",
    "\n",
    "# YOLO dataset structure paths\n",
    "IMG_TRAIN_DIR = os.path.join(OUTPUT_YOLO_DATA_DIR, \"images/train\")\n",
    "LBL_TRAIN_DIR = os.path.join(OUTPUT_YOLO_DATA_DIR, \"labels/train\")\n",
    "IMG_VAL_DIR = os.path.join(OUTPUT_YOLO_DATA_DIR, \"images/val\")\n",
    "LBL_VAL_DIR = os.path.join(OUTPUT_YOLO_DATA_DIR, \"labels/val\")\n",
    "\n",
    "# Parameters\n",
    "VAL_SPLIT = 0.20 # 20% validation split\n",
    "CLASS_NAME = \"Ripe\"\n",
    "CLASS_ID = 0 # YOLO class IDs are 0-indexed\n",
    "\n",
    "# Training Hyperparameters (adjust as needed)\n",
    "EPOCHS = 30 # Start with a moderate number\n",
    "IMG_SIZE = 640 # Standard YOLOv8 input size\n",
    "BATCH_SIZE = 16 # Adjust based on GPU memory (16 is often a good start)\n",
    "MODEL_NAME = 'yolov8n.pt' # Nano version - fast, less accurate\n",
    "PROJECT_NAME = '/kaggle/working/yolo_training_results'\n",
    "RUN_NAME = 'mango_ripe_only_run'\n",
    "\n",
    "#------------------------------------------------------\n",
    "# 3. Prepare Dataset in YOLO Format\n",
    "#------------------------------------------------------\n",
    "print(\"Preparing dataset in YOLO format...\")\n",
    "\n",
    "# Create necessary directories\n",
    "os.makedirs(IMG_TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(LBL_TRAIN_DIR, exist_ok=True)\n",
    "os.makedirs(IMG_VAL_DIR, exist_ok=True)\n",
    "os.makedirs(LBL_VAL_DIR, exist_ok=True)\n",
    "\n",
    "# Get list of ripe images\n",
    "ripe_images = [f for f in os.listdir(RIPE_IMG_DIR) if os.path.isfile(os.path.join(RIPE_IMG_DIR, f))]\n",
    "random.shuffle(ripe_images) # Shuffle for random split\n",
    "\n",
    "# Split into train and validation sets\n",
    "split_idx = int(len(ripe_images) * (1 - VAL_SPLIT))\n",
    "train_images = ripe_images[:split_idx]\n",
    "val_images = ripe_images[split_idx:]\n",
    "\n",
    "print(f\"Total 'Ripe' images: {len(ripe_images)}\")\n",
    "print(f\"Training images: {len(train_images)}\")\n",
    "print(f\"Validation images: {len(val_images)}\")\n",
    "\n",
    "# --- Function to create pseudo-annotation (whole image) ---\n",
    "def create_pseudo_label(image_filename, label_dir):\n",
    "    \"\"\"\n",
    "    Creates a YOLO label file assuming the object covers the entire image.\n",
    "    Format: <class_id> <x_center> <y_center> <width> <height> (normalized)\n",
    "    \"\"\"\n",
    "    label_filename = os.path.splitext(image_filename)[0] + \".txt\"\n",
    "    label_path = os.path.join(label_dir, label_filename)\n",
    "    with open(label_path, 'w') as f:\n",
    "        # Class 0, center (0.5, 0.5), width 1.0, height 1.0\n",
    "        f.write(f\"{CLASS_ID} 0.5 0.5 1.0 1.0\\n\")\n",
    "\n",
    "# --- Process Training Images ---\n",
    "print(\"Processing Training Set...\")\n",
    "for img_name in train_images:\n",
    "    # Copy image\n",
    "    shutil.copy(os.path.join(RIPE_IMG_DIR, img_name), os.path.join(IMG_TRAIN_DIR, img_name))\n",
    "    # Create pseudo-label\n",
    "    create_pseudo_label(img_name, LBL_TRAIN_DIR)\n",
    "\n",
    "# --- Process Validation Images ---\n",
    "print(\"Processing Validation Set...\")\n",
    "for img_name in val_images:\n",
    "    # Copy image\n",
    "    shutil.copy(os.path.join(RIPE_IMG_DIR, img_name), os.path.join(IMG_VAL_DIR, img_name))\n",
    "    # Create pseudo-label\n",
    "    create_pseudo_label(img_name, LBL_VAL_DIR)\n",
    "\n",
    "print(\"Dataset preparation finished.\")\n",
    "print(\"--- IMPORTANT NOTE ---\")\n",
    "print(\"Generated labels assume the *entire image* is the 'Ripe' mango.\")\n",
    "print(\"For true object detection, bounding box annotations are required.\")\n",
    "print(\"----------------------\")\n",
    "\n",
    "\n",
    "#------------------------------------------------------\n",
    "# 4. Create data.yaml file for YOLO\n",
    "#------------------------------------------------------\n",
    "yaml_data = {\n",
    "    'train': IMG_TRAIN_DIR,\n",
    "    'val': IMG_VAL_DIR,\n",
    "    'nc': 1, # Number of classes\n",
    "    'names': [CLASS_NAME] # List of class names\n",
    "}\n",
    "\n",
    "yaml_file_path = os.path.join(OUTPUT_YOLO_DATA_DIR, \"data.yaml\")\n",
    "\n",
    "with open(yaml_file_path, 'w') as f:\n",
    "    yaml.dump(yaml_data, f, default_flow_style=False)\n",
    "\n",
    "print(f\"data.yaml created at: {yaml_file_path}\")\n",
    "# You can print the content to verify\n",
    "# !cat {yaml_file_path}\n",
    "\n",
    "#------------------------------------------------------\n",
    "# 5. Train the YOLOv8 Model\n",
    "#------------------------------------------------------\n",
    "print(\"Starting YOLOv8 training...\")\n",
    "\n",
    "# Load a pretrained YOLOv8n model\n",
    "model = YOLO(MODEL_NAME)\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data=yaml_file_path,\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH_SIZE,\n",
    "    project=PROJECT_NAME,\n",
    "    name=RUN_NAME,\n",
    "    # patience=10, # Optional: Early stopping patience\n",
    "    # device=0 # Optional: Specify GPU device (0 usually works in Kaggle)\n",
    ")\n",
    "\n",
    "print(\"Training finished.\")\n",
    "print(f\"Results saved to: {PROJECT_NAME}/{RUN_NAME}\")\n",
    "\n",
    "#------------------------------------------------------\n",
    "# 6. (Optional) View Results / Example Prediction\n",
    "#------------------------------------------------------\n",
    "# You can find the best model weights at:\n",
    "# /kaggle/working/yolo_training_results/mango_ripe_only_run/weights/best.pt\n",
    "\n",
    "# Example of loading the trained model and predicting on a validation image\n",
    "print(\"\\nExample Prediction:\")\n",
    "trained_model_path = os.path.join(PROJECT_NAME, RUN_NAME, 'weights/best.pt')\n",
    "if os.path.exists(trained_model_path) and val_images:\n",
    "    # Load the trained model\n",
    "    trained_model = YOLO(trained_model_path)\n",
    "\n",
    "    # Select a random validation image\n",
    "    sample_image_name = random.choice(val_images)\n",
    "    sample_image_path = os.path.join(IMG_VAL_DIR, sample_image_name)\n",
    "\n",
    "    print(f\"Predicting on: {sample_image_path}\")\n",
    "    # Run prediction\n",
    "    predict_results = trained_model.predict(source=sample_image_path, save=True) # save=True saves the image with boxes\n",
    "\n",
    "    # The predicted image will be saved in /kaggle/working/runs/detect/predict...\n",
    "    # Display the saved image (find the latest prediction folder)\n",
    "    try:\n",
    "        predict_dir = sorted([d for d in os.listdir('/kaggle/working/runs/detect') if d.startswith('predict')], reverse=True)[0]\n",
    "        output_image_path = os.path.join('/kaggle/working/runs/detect', predict_dir, sample_image_name)\n",
    "        if os.path.exists(output_image_path):\n",
    "            print(\"Displaying prediction result:\")\n",
    "            display(Image(filename=output_image_path))\n",
    "        else:\n",
    "             print(f\"Could not find predicted image at expected location: {output_image_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not display prediction image: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"Could not find trained model or validation images for prediction example.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# [Your previous YOLOv8 training code should be above this]\n",
    "# Ensure the following variables are defined from your training script:\n",
    "# - results: The object returned by model.train()\n",
    "# - PROJECT_NAME: e.g., '/kaggle/working/yolo_training_results'\n",
    "# - RUN_NAME: e.g., 'mango_ripe_only_run'\n",
    "# - EPOCHS: The number of epochs used for training\n",
    "# - IMG_SIZE: The image size used for training (e.g., 640)\n",
    "# - MODEL_NAME: The base model used (e.g., 'yolov8n.pt')\n",
    "\n",
    "# Define the path to the best model reliably\n",
    "# best_model_path = os.path.join(PROJECT_NAME, RUN_NAME, 'weights/best.pt')\n",
    "\n",
    "# # ------------------------------------\n",
    "# # 7. Save Model to Hugging Face Hub\n",
    "# # ------------------------------------\n",
    "# print(\"\\nAttempting to upload model to Hugging Face Hub...\")\n",
    "\n",
    "# # First, check if the best model file actually exists\n",
    "# if not os.path.exists(best_model_path):\n",
    "#     print(f\"❌ Error: Best model not found at {best_model_path}. Skipping Hugging Face upload.\")\n",
    "#     print(\"This might happen if the training failed or did not produce 'best.pt'.\")\n",
    "# else:\n",
    "#     try:\n",
    "#         # Install the huggingface_hub package if not already installed\n",
    "#         !pip install huggingface_hub -q\n",
    "\n",
    "#         # Import necessary packages\n",
    "#         from huggingface_hub import HfApi, login\n",
    "#         import shutil\n",
    "#         import datetime # To get the current date for the README\n",
    "\n",
    "#         # --- IMPORTANT: SECURITY RECOMMENDATION ---\n",
    "#         # Avoid hardcoding tokens. Use Kaggle Secrets for better security.\n",
    "#         # 1. Go to \"Add-ons\" -> \"Secrets\" in your Kaggle notebook.\n",
    "#         # 2. Add a secret named \"HF_TOKEN\" with your Hugging Face write token as the value.\n",
    "#         # 3. Uncomment the following lines to use the secret:\n",
    "#         # from kaggle_secrets import UserSecretsClient\n",
    "#         # user_secrets = UserSecretsClient()\n",
    "#         # hf_token = user_secrets.get_secret(\"HF_TOKEN\")\n",
    "#         # print(\"Using Hugging Face token from Kaggle Secrets.\")\n",
    "#         # --- For this example, using the provided token (less secure) ---\n",
    "#         hf_token = \"your_tokenhf_NWCRwmEBVFlNmHjomfgdZwnTOSvPYAfGWU\" # Replace with your actual token or use Secrets\n",
    "#         if hf_token == \"your_token\": # Basic check if default token is used\n",
    "#              print(\"⚠️ WARNING: Using a hardcoded Hugging Face token. Consider using Kaggle Secrets.\")\n",
    "\n",
    "#         print(\"Logging into Hugging Face Hub...\")\n",
    "#         # add_to_git_credential=False is often helpful in non-interactive environments like Kaggle\n",
    "#         login(token=hf_token, add_to_git_credential=False)\n",
    "#         print(\"Login successful.\")\n",
    "\n",
    "#         # Define the repository name and create a local directory for upload files\n",
    "#         repo_id = \"sravan27745/yolo_mangop\" # Your HF username / desired repo name\n",
    "#         # Use /kaggle/working/ as it's the writable directory in Kaggle\n",
    "#         local_dir = \"/kaggle/working/hf_model_upload\"\n",
    "\n",
    "#         # Create the temporary directory for the files to upload\n",
    "#         os.makedirs(local_dir, exist_ok=True)\n",
    "#         print(f\"Created local directory for upload: {local_dir}\")\n",
    "\n",
    "#         # Copy the best model weights to the upload directory\n",
    "#         shutil.copy(best_model_path, os.path.join(local_dir, \"best.pt\"))\n",
    "#         print(f\"Copied best model weights ({best_model_path}) to upload directory.\")\n",
    "\n",
    "#         # --- Create a README.md file with relevant model information ---\n",
    "#         readme_path = os.path.join(local_dir, \"README.md\")\n",
    "#         print(f\"Creating {readme_path}...\")\n",
    "\n",
    "#         # Extract base model name (e.g., 'yolov8n' from 'yolov8n.pt')\n",
    "#         base_model_name = MODEL_NAME.replace('.pt', '')\n",
    "#         training_date = datetime.datetime.now().strftime(\"%Y-%m-%d\") # Get current date\n",
    "\n",
    "#         # Class name comes from the training script\n",
    "#         trained_class_name = CLASS_NAME # Should be 'Ripe' based on previous code\n",
    "\n",
    "#         readme_content = f\"\"\"---\n",
    "# language: en\n",
    "# license: mit # Or choose another appropriate license\n",
    "# library_name: ultralytics\n",
    "# tags:\n",
    "# - yolov8\n",
    "# - object-detection\n",
    "# - computer-vision\n",
    "# - mangoes\n",
    "# - agriculture\n",
    "# - ripe-mango\n",
    "# datasets:\n",
    "# - custom-mango-classification # Describe your dataset source if possible\n",
    "# pipeline_tag: object-detection\n",
    "# widget:\n",
    "# - src: https://ultralytics.com/images/bus.jpg # Example image for widget\n",
    "#   example_title: YOLOv8 Ripe Mango Detection Example\n",
    "# ---\n",
    "\n",
    "# # YOLOv8 Ripe Mango Detection Model (Classification-based)\n",
    "\n",
    "# This model was trained using the Ultralytics YOLOv8 library to detect **ripe mangoes**.\n",
    "\n",
    "# ## Model Details\n",
    "# - **Base model:** `{base_model_name}`\n",
    "# - **Class detected:** '{trained_class_name}' (Class ID 0)\n",
    "# - **Epochs trained:** `{EPOCHS}`\n",
    "# - **Input size:** `{IMG_SIZE}x{IMG_SIZE}`\n",
    "# - **Training date:** `{training_date}`\n",
    "\n",
    "# ## Training Data & Approach\n",
    "# This model was trained on a dataset originally structured for image classification (folders: OverRipe, Ripe, UnRipe). Only images from the **'{trained_class_name}'** category were used for training this specific detection model.\n",
    "\n",
    "# **Important Note:** During training, pseudo-labels were generated assuming the ripe mango object covers the *entire* image frame (YOLO format: `0 0.5 0.5 1.0 1.0`). Therefore, while it uses a detection framework, its primary function based on this training is closer to classifying if an image contains a ripe mango. For precise bounding box localization *within* an image containing multiple objects or backgrounds, fine-tuning with accurate bounding box annotations is necessary.\n",
    "\n",
    "# ## Usage\n",
    "# Make sure you have `ultralytics` and `torch` installed:\n",
    "# ```bash\n",
    "# pip install ultralytics torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # ------------------------------------\n",
    "# # 1. Install/Ensure Libraries\n",
    "# # ------------------------------------\n",
    "# # Need ultralytics for YOLO and gradio for the interface\n",
    "# # Also ensure transformers and huggingface_hub are available for HF integration\n",
    "# !pip install ultralytics gradio transformers huggingface_hub torch -q # Ensure torch is also there\n",
    "# print(\"Ultralytics, Gradio, Transformers, Hub, and Torch libraries installed/updated.\")\n",
    "\n",
    "# # ------------------------------------\n",
    "# # 2. Import Libraries\n",
    "# # ------------------------------------\n",
    "# import os\n",
    "# import gradio as gr\n",
    "# from ultralytics import YOLO\n",
    "# from PIL import Image\n",
    "# import numpy as np # Use standard 'np' alias\n",
    "# import glob # To find example images if needed\n",
    "# import torch # Import torch explicitly for potential device checks later\n",
    "\n",
    "# print(\"Libraries imported.\")\n",
    "\n",
    "# # ------------------------------------\n",
    "# # 3. Define Hugging Face Model ID\n",
    "# # ------------------------------------\n",
    "# # Your Hugging Face repository ID (username/repo_name)\n",
    "# hf_model_id = \"sravan27745/yolo_mangop\"\n",
    "# print(f\"Using Hugging Face Hub model repository ID: {hf_model_id}\")\n",
    "\n",
    "# # ------------------------------------\n",
    "# # 4. Load the YOLO Model from Hugging Face\n",
    "# # ------------------------------------\n",
    "# print(f\"Attempting to load YOLOv8 model directly from Hugging Face Hub repo: {hf_model_id}...\")\n",
    "# # Ultralytics' YOLO class is often smart enough to find 'best.pt' or other standard weights\n",
    "# # within the specified repository automatically.\n",
    "# try:\n",
    "#     # Load the model using just the repo ID\n",
    "#     model = YOLO(hf_model_id)\n",
    "#     print(f\"YOLOv8 model loaded successfully from {hf_model_id}.\")\n",
    "#     # Optional: Print model info (helpful for debugging)\n",
    "#     model.info()\n",
    "#     # You can check the specific class name loaded\n",
    "#     print(f\"Model trained for classes: {model.names}\")\n",
    "#     if 0 in model.names:\n",
    "#          detected_class_name = model.names[0] # Assuming 'Ripe' is class 0\n",
    "#          print(f\"Assuming Class ID 0 corresponds to '{detected_class_name}' based on training.\")\n",
    "#     else:\n",
    "#          detected_class_name = \"Detected Object\" # Fallback name\n",
    "#          print(\"Warning: Could not automatically determine the name for Class ID 0.\")\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(f\"❌ Error loading model from Hugging Face repo '{hf_model_id}': {e}\")\n",
    "#     print(\"\\nTroubleshooting:\")\n",
    "#     print(f\"  1. Ensure the repository '{hf_model_id}' exists and is PUBLIC on Hugging Face Hub.\")\n",
    "#     print(f\"  2. Ensure a valid YOLOv8 model file (like 'best.pt') exists at the root of that repository.\")\n",
    "#     print(f\"  3. Check your internet connection from the Kaggle kernel.\")\n",
    "#     print(f\"  4. As a fallback, you can try specifying the file explicitly: model = YOLO('{hf_model_id}/best.pt')\")\n",
    "#     # Stop execution if model loading fails\n",
    "#     raise RuntimeError(f\"Failed to load model {hf_model_id}\") from e\n",
    "\n",
    "# # ------------------------------------\n",
    "# # 5. Define Inference Function\n",
    "# # ------------------------------------\n",
    "# def detect_ripe_mangoes(input_image: Image.Image, confidence_threshold: float = 0.25):\n",
    "#     \"\"\"\n",
    "#     Performs inference on the input image using the loaded YOLOv8 model\n",
    "#     to detect the 'Ripe' mango class (as trained).\n",
    "\n",
    "#     Args:\n",
    "#         input_image (PIL.Image.Image): Image uploaded by the user.\n",
    "#         confidence_threshold (float): Minimum confidence score for detections.\n",
    "\n",
    "#     Returns:\n",
    "#         tuple(PIL.Image.Image, str): Annotated image and status message.\n",
    "#     \"\"\"\n",
    "#     if input_image is None:\n",
    "#         # Return a placeholder or blank image if needed by Gradio output component\n",
    "#         # Create a small blank image\n",
    "#         blank_image = Image.new('RGB', (200, 100), color = 'grey')\n",
    "#         # You could potentially draw text on it too if desired\n",
    "#         return blank_image, \"Status: Please upload an image.\"\n",
    "\n",
    "#     print(f\"Received image for inference. Type: {type(input_image)}\")\n",
    "#     print(f\"Running inference with confidence threshold: {confidence_threshold}\")\n",
    "\n",
    "#     # Perform inference using the loaded 'model'\n",
    "#     # device=0 forces GPU if available, remove or set to 'cpu' if needed\n",
    "#     try:\n",
    "#         # Setting verbose=False to reduce console spam during prediction\n",
    "#         results = model.predict(source=input_image, conf=confidence_threshold, device=None, save=False, verbose=False) # Use None for auto-device selection\n",
    "#     except Exception as pred_e:\n",
    "#         print(f\"Error during model.predict: {pred_e}\")\n",
    "#         # Return original image and error message\n",
    "#         return input_image, f\"Status: Error during prediction: {pred_e}\"\n",
    "\n",
    "\n",
    "#     if not results:\n",
    "#         print(\"Warning: model.predict returned None or empty list.\")\n",
    "#         return input_image, \"Status: Prediction returned no results.\"\n",
    "\n",
    "#     # Assuming prediction on a single image, get the first result object\n",
    "#     result = results[0]\n",
    "\n",
    "#     # Get the annotated image as a NumPy array (BGR format by default)\n",
    "#     # Plotting includes boxes, labels, and confidence scores\n",
    "#     annotated_image_np = result.plot(conf=True) # Set conf=True to show confidence on boxes\n",
    "\n",
    "#     # Convert NumPy array (BGR) back to PIL Image (RGB) for Gradio display\n",
    "#     annotated_image_pil = Image.fromarray(annotated_image_np[..., ::-1]) # Correct BGR to RGB conversion\n",
    "\n",
    "#     num_detections = len(result.boxes)\n",
    "#     class_name_display = detected_class_name # Use the name determined during model load\n",
    "\n",
    "#     if num_detections > 0:\n",
    "#          # Optional: Get confidences if needed\n",
    "#          # confs = result.boxes.conf.tolist()\n",
    "#          status_message = f\"Status: Detected {num_detections} instance(s) of '{class_name_display}'.\"\n",
    "#     else:\n",
    "#          status_message = f\"Status: No '{class_name_display}' detected with confidence >= {confidence_threshold:.2f}.\"\n",
    "\n",
    "#     print(status_message) # Log status to notebook console\n",
    "\n",
    "#     return annotated_image_pil, status_message\n",
    "\n",
    "# # ------------------------------------\n",
    "# # 6. Find Example Images (Optional - Requires Dataset Input)\n",
    "# # ------------------------------------\n",
    "# # --- IMPORTANT ---\n",
    "# # This section requires the original dataset (or at least some sample images)\n",
    "# # to be attached to the Kaggle notebook's input.\n",
    "# # Update the path '/kaggle/input/your_dataset_name/path/to/images' accordingly.\n",
    "# # If the dataset isn't attached, this will be skipped gracefully.\n",
    "# # -----------------\n",
    "# example_image_dir = '/kaggle/input/classification/dataset1/Ripe' # ADJUST THIS PATH if needed! (Using Ripe folder from original structure)\n",
    "# example_images = []\n",
    "\n",
    "# print(f\"\\nLooking for example images in: {example_image_dir}\")\n",
    "# if os.path.isdir(example_image_dir):\n",
    "#     image_patterns = ['*.jpg', '*.jpeg', '*.png', '*.webp'] # Add common image types\n",
    "#     found_files = []\n",
    "#     for pattern in image_patterns:\n",
    "#          # Use recursive=True if images might be in subdirectories\n",
    "#          found_files.extend(glob.glob(os.path.join(example_image_dir, pattern))) # Removed recursive for simplicity\n",
    "\n",
    "#     # Remove duplicates and limit the number of examples\n",
    "#     example_images = sorted(list(set(found_files)))[:5] # Get up to 5 examples\n",
    "\n",
    "#     if example_images:\n",
    "#         print(f\"Found {len(example_images)} example images:\")\n",
    "#         for ex_img in example_images:\n",
    "#              print(f\"  - {os.path.basename(ex_img)}\") # Print only filename for brevity\n",
    "#     else:\n",
    "#         print(\"Found the directory, but no image files matching patterns.\")\n",
    "# else:\n",
    "#     print(f\"Example image directory not found or inaccessible: {example_image_dir}\")\n",
    "#     print(\"Ensure the dataset is correctly attached to the notebook under '/kaggle/input/'.\")\n",
    "#     print(\"Examples section will be skipped.\")\n",
    "\n",
    "\n",
    "# # ------------------------------------\n",
    "# # 7. Create and Launch Gradio Interface\n",
    "# # ------------------------------------\n",
    "# print(\"\\nSetting up Gradio interface...\")\n",
    "\n",
    "# # Use gr.Blocks for more layout control\n",
    "# with gr.Blocks(theme=gr.themes.Soft()) as demo: # Added a theme for nicer look\n",
    "#     gr.Markdown(f\"\"\"\n",
    "#     # YOLOv8 'Ripe' Mango Detector 🥭\n",
    "#     Detects the '{detected_class_name}' class using a model fine-tuned from YOLOv8.\n",
    "#     Model loaded from Hugging Face Hub: `{hf_model_id}`.\n",
    "#     **Note:** This model was trained assuming the ripe mango fills most of the image (using classification-style data). Performance may vary on complex scenes.\n",
    "#     \"\"\")\n",
    "\n",
    "#     with gr.Row():\n",
    "#         with gr.Column(scale=1):\n",
    "#             input_img = gr.Image(type=\"pil\", label=\"Upload Mango Image\")\n",
    "#             conf_slider = gr.Slider(minimum=0.10, maximum=0.95, value=0.25, step=0.05, label=\"Confidence Threshold\")\n",
    "#             submit_btn = gr.Button(\"🔍 Detect Mangoes\", variant=\"primary\") # Make button stand out\n",
    "\n",
    "#         with gr.Column(scale=1):\n",
    "#             output_img = gr.Image(type=\"pil\", label=\"Output Image with Detections\")\n",
    "#             status_text = gr.Textbox(label=\"Detection Status\", interactive=False) # To show detection count/messages\n",
    "\n",
    "#     if example_images:\n",
    "#         print(\"Creating Gradio examples...\")\n",
    "#         gr.Examples(\n",
    "#             examples=example_images,\n",
    "#             inputs=input_img, # The component where examples are loaded\n",
    "#             outputs=[output_img, status_text], # Components to display results in\n",
    "#             fn=detect_ripe_mangoes, # Function to call for examples\n",
    "#             # Cache results for examples to speed up loading after first click\n",
    "#             # Be cautious with caching if your function has side effects or uses external state that changes\n",
    "#             cache_examples=False, # Set to True if function is pure and dataset is static\n",
    "#             # Define how many examples per page, adjust as needed\n",
    "#             examples_per_page=5\n",
    "#         )\n",
    "#     else:\n",
    "#          gr.Markdown(\"_(Example images could not be loaded. Attach the dataset to enable examples.)_\")\n",
    "\n",
    "#     # Connect the button click to the inference function\n",
    "#     submit_btn.click(\n",
    "#         fn=detect_ripe_mangoes,\n",
    "#         inputs=[input_img, conf_slider],\n",
    "#         outputs=[output_img, status_text]\n",
    "#     )\n",
    "\n",
    "# print(\"\\nLaunching Gradio interface...\")\n",
    "# print(\"Please wait for the public URL to appear below...\")\n",
    "# # Launch the interface.\n",
    "# # share=True generates a public link (essential for running in Kaggle/Colab)\n",
    "# # debug=True provides logs in the notebook output, helpful for troubleshooting\n",
    "# # inline=False opens the interface in a new tab (often better for layout)\n",
    "# demo.launch(share=True, debug=True, inline=False)\n",
    "\n",
    "# print(\"\\n----------------------------------------------------------------------\")\n",
    "# print(\"Gradio Setup Complete. If successful, a public URL should be visible above.\")\n",
    "# print(\"If the interface doesn't load, check the output logs for errors.\")\n",
    "# print(\"Remember to STOP the Kaggle kernel when you are finished.\")\n",
    "# print(\"----------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7287227,
     "sourceId": 11616655,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
